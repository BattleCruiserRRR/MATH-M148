{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd572a5-9b74-400f-ac11-2bd82131edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebfc4aa2-006e-4e34-ae69-20a8da9f1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f968ee84-c6d6-4d49-997b-1ba341d55fab",
   "metadata": {},
   "source": [
    "**1. Data Preprocessing Based on Luke's Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33fb272-f28d-4286-98d7-4afdd7cf2dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data = pd.read_csv('no_dup_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabdbe2d-bdd2-47c4-b15a-ef76ed4bbd1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>ed_id</th>\n",
       "      <th>event_name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>journey_steps_until_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-784961211</td>\n",
       "      <td>1773350293</td>\n",
       "      <td>12</td>\n",
       "      <td>application_web_approved</td>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>08:45:22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-784961211</td>\n",
       "      <td>1773350293</td>\n",
       "      <td>19</td>\n",
       "      <td>application_web_view</td>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>13:32:10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>-784961211</td>\n",
       "      <td>1773350293</td>\n",
       "      <td>3</td>\n",
       "      <td>application_web_submit</td>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>13:32:10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>-784961211</td>\n",
       "      <td>1773350293</td>\n",
       "      <td>2</td>\n",
       "      <td>campaign_click</td>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>14:45:22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>-784961211</td>\n",
       "      <td>1773350293</td>\n",
       "      <td>19</td>\n",
       "      <td>application_web_view</td>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>14:57:56</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>-784961211</td>\n",
       "      <td>1773350293</td>\n",
       "      <td>19</td>\n",
       "      <td>application_web_view</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>16:01:06</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>15849251</td>\n",
       "      <td>383997507</td>\n",
       "      <td>4</td>\n",
       "      <td>browse_products</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>14:11:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25</td>\n",
       "      <td>15849251</td>\n",
       "      <td>383997507</td>\n",
       "      <td>4</td>\n",
       "      <td>browse_products</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>14:11:29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>15849251</td>\n",
       "      <td>383997507</td>\n",
       "      <td>4</td>\n",
       "      <td>browse_products</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>14:12:10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27</td>\n",
       "      <td>15849251</td>\n",
       "      <td>383997507</td>\n",
       "      <td>4</td>\n",
       "      <td>browse_products</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>14:12:21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  customer_id  account_id  ed_id                event_name  \\\n",
       "0           0   -784961211  1773350293     12  application_web_approved   \n",
       "1           1   -784961211  1773350293     19      application_web_view   \n",
       "2          14   -784961211  1773350293      3    application_web_submit   \n",
       "3          15   -784961211  1773350293      2            campaign_click   \n",
       "4          16   -784961211  1773350293     19      application_web_view   \n",
       "5          21   -784961211  1773350293     19      application_web_view   \n",
       "6          24     15849251   383997507      4           browse_products   \n",
       "7          25     15849251   383997507      4           browse_products   \n",
       "8          26     15849251   383997507      4           browse_products   \n",
       "9          27     15849251   383997507      4           browse_products   \n",
       "\n",
       "         Date      Time  journey_steps_until_end  \n",
       "0  2023-03-22  08:45:22                        1  \n",
       "1  2023-03-22  13:32:10                        2  \n",
       "2  2023-03-22  13:32:10                        3  \n",
       "3  2023-03-22  14:45:22                        4  \n",
       "4  2023-07-27  14:57:56                        5  \n",
       "5  2023-08-29  16:01:06                        6  \n",
       "6  2021-11-04  14:11:15                        1  \n",
       "7  2021-11-04  14:11:29                        2  \n",
       "8  2021-11-04  14:12:10                        3  \n",
       "9  2021-11-04  14:12:21                        4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd714221-0ede-4525-83fa-bed66ab32efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55853910, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a7b544-2038-473d-b620-e1c7363e4a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function to randomly sample from the original data for further RNN \n",
    "def bagging_func(n, whole_data):\n",
    "    account_ids = whole_data['account_id'].unique()\n",
    "    \n",
    "    sub_account_id = np.random.choice(account_ids, size=n, replace=False)\n",
    "    sample_f_data = whole_data[whole_data['account_id'].isin(sub_account_id)]\n",
    "\n",
    "    return sample_f_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1749877-db17-4523-b412-b73e9c53c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = bagging_func(1000, f_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc32d89-12a0-4bd1-9858-cbc3382038e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getting all journeys for each account\n",
    "def journey_list(sample_f_data):\n",
    "    ed_id_lists = sample_f_data.groupby(['account_id'])['ed_id'].apply(list).reset_index()\n",
    "    \n",
    "    max_length = ed_id_lists['ed_id'].apply(len).max()\n",
    "    ed_id_lists['ed_id'] = ed_id_lists['ed_id'].apply(lambda x: x + [0] * (max_length - len(x)))\n",
    "    \n",
    "    return ed_id_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92d8bece-0059-48ac-8c6d-7282fc36488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code of Luke, possible future modifications, which defines what is the ultimate result\n",
    "def event_label(x):\n",
    "    act_list = np.array([29,12,15])\n",
    "    ord_list = np.array([7,18])\n",
    "\n",
    "    is_act = False\n",
    "    is_ord = False\n",
    "\n",
    "    # parse and get condition checks\n",
    "    # if any activated, \n",
    "    if any(np.in1d(x,act_list)):\n",
    "        is_act = True\n",
    "    if any(np.in1d(x,ord_list)):\n",
    "        is_ord = True\n",
    "\n",
    "    # activated only\n",
    "    if is_act == True and is_ord == False:\n",
    "        return \"Activated, No Order\"\n",
    "\n",
    "    # ordered only\n",
    "    elif is_act == False and is_ord == True:\n",
    "        return \"Ordered, Not Activated\"\n",
    "\n",
    "    # activated and ordered\n",
    "    elif is_act == True and is_ord == True:\n",
    "        return \"Activated and Ordered\"\n",
    "    \n",
    "    # accounts neither fit\n",
    "    else:\n",
    "        return \"Neither\"\n",
    "\n",
    "# vectorize function\n",
    "event_label_vec = np.vectorize(event_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f63518b0-8b91-4340-adf0-990693159d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard useless labels, getting only the necessary labels for RNN model\n",
    "def binary_labels(ed_id_lists):\n",
    "    necessary_labels = [\"Activated, No Order\", \"Activated and Ordered\"]\n",
    "    ed_id_lists = ed_id_lists[ed_id_lists['customer_label'].isin(necessary_labels)]\n",
    "\n",
    "    return ed_id_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd21010e-3740-4d1b-8218-67b7dcf26788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning `customer_label` to true labels\n",
    "def true_labels(ed_id_lists):\n",
    "    codes, uniques = pd.factorize(ed_id_lists['customer_label'])\n",
    "    ed_id_lists['customer_label'] = codes\n",
    "\n",
    "    return ed_id_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba7ec494-6f9a-4d51-9e94-cc2fda1ae044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the previous functions together\n",
    "def preprocessing(n, f_data):\n",
    "    sample_f_data = bagging_func(n, f_data)\n",
    "    sample_f_data = sample_f_data[['customer_id', 'account_id', 'ed_id', 'journey_steps_until_end']]\n",
    "    \n",
    "    ed_id_lists = journey_list(sample_f_data)\n",
    "    ed_id_lists[\"customer_label\"] = event_label_vec(ed_id_lists[\"ed_id\"])\n",
    "\n",
    "    ed_id_lists = binary_labels(ed_id_lists)\n",
    "    ed_id_lists = true_labels(ed_id_lists)\n",
    "\n",
    "    return ed_id_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94fd2564-6e3c-4ba3-abdf-c5a10c9cff7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>ed_id</th>\n",
       "      <th>customer_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2126367060</td>\n",
       "      <td>[2, 12, 5, 4, 5, 4, 4, 4, 4, 4, 4, 11, 4, 4, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2115929492</td>\n",
       "      <td>[2, 12, 11, 1, 5, 6, 5, 5, 1, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2114878072</td>\n",
       "      <td>[19, 19, 19, 3, 19, 12, 19, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2093667389</td>\n",
       "      <td>[2, 12, 1, 1, 1, 24, 1, 24, 24, 24, 1, 1, 5, 6...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2090522827</td>\n",
       "      <td>[2, 19, 3, 19, 19, 3, 19, 19, 3, 19, 3, 19, 3,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2082736687</td>\n",
       "      <td>[12, 4, 1, 6, 4, 11, 5, 6, 4, 11, 5, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2062755641</td>\n",
       "      <td>[1, 1, 1, 19, 19, 19, 19, 19, 19, 3, 19, 12, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2059967457</td>\n",
       "      <td>[19, 19, 19, 19, 19, 19, 3, 12, 4, 4, 4, 4, 4,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2059070041</td>\n",
       "      <td>[21, 22, 2, 12, 19, 19, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2057671282</td>\n",
       "      <td>[29, 12, 6, 11, 7, 5, 4, 8, 11, 5, 4, 19, 5, 4...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id                                              ed_id  \\\n",
       "0 -2126367060  [2, 12, 5, 4, 5, 4, 4, 4, 4, 4, 4, 11, 4, 4, 1...   \n",
       "1 -2115929492  [2, 12, 11, 1, 5, 6, 5, 5, 1, 0, 0, 0, 0, 0, 0...   \n",
       "2 -2114878072  [19, 19, 19, 3, 19, 12, 19, 4, 4, 4, 4, 4, 4, ...   \n",
       "3 -2093667389  [2, 12, 1, 1, 1, 24, 1, 24, 24, 24, 1, 1, 5, 6...   \n",
       "4 -2090522827  [2, 19, 3, 19, 19, 3, 19, 19, 3, 19, 3, 19, 3,...   \n",
       "5 -2082736687  [12, 4, 1, 6, 4, 11, 5, 6, 4, 11, 5, 0, 0, 0, ...   \n",
       "6 -2062755641  [1, 1, 1, 19, 19, 19, 19, 19, 19, 3, 19, 12, 1...   \n",
       "7 -2059967457  [19, 19, 19, 19, 19, 19, 3, 12, 4, 4, 4, 4, 4,...   \n",
       "8 -2059070041  [21, 22, 2, 12, 19, 19, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "9 -2057671282  [29, 12, 6, 11, 7, 5, 4, 8, 11, 5, 4, 19, 5, 4...   \n",
       "\n",
       "   customer_label  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "5               0  \n",
       "6               0  \n",
       "7               0  \n",
       "8               0  \n",
       "9               1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take part of the dataset\n",
    "ed_id_lists = preprocessing(1000, f_data)\n",
    "ed_id_lists.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8272b210-310a-4deb-9ea1-7d2b8d936368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed_id_lists.customer_label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03c9e39a-30d6-4e76-8fdf-ff14614a4f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        0.198000\n",
       "std         0.398692\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000\n",
       "Name: customer_label, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed_id_lists['customer_label'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a34ef-efce-460e-95e6-756779daa333",
   "metadata": {},
   "source": [
    "**2. Building RNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65e7b697-0bbc-4ccd-bf1c-4f52a8536b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(input_lists, split = 0.2, b_size = 128):\n",
    "    # adding masks for each observation\n",
    "    X = input_lists['ed_id']  # Features\n",
    "    X = X.values.tolist()\n",
    "    mask = [[1 if x > 0 else x for x in sublist] for sublist in X]\n",
    "    y = input_lists['customer_label']  # Target variable\n",
    "    y = y.values.tolist()\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test, mask_train, mask_test = train_test_split(X, y, mask, test_size=split, random_state=42)\n",
    "\n",
    "    train_dset = torch.utils.data.TensorDataset(torch.tensor(X_train,\n",
    "                                                         dtype=torch.long),\n",
    "                                            torch.tensor(y_train,\n",
    "                                                         dtype=torch.long),\n",
    "                                            torch.tensor(mask_train,\n",
    "                                                         dtype=torch.float))\n",
    "\n",
    "    test_dset = torch.utils.data.TensorDataset(torch.tensor(X_test,\n",
    "                                                            dtype=torch.long),\n",
    "                                              torch.tensor(y_test,\n",
    "                                                            dtype=torch.long),\n",
    "                                              torch.tensor(mask_test,\n",
    "                                                            dtype=torch.float))\n",
    "    \n",
    "    # getting data loader for training and predicting process\n",
    "    batch_size = b_size\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=2,\n",
    "                              drop_last=True\n",
    "                             )\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(test_dset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=2,\n",
    "                              drop_last=True\n",
    "                             )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43c01968-c03f-44d9-a541-c9fd6a8305d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = data_loader(ed_id_lists, split = 0.2, b_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14cb9626-7fe3-4f2a-ab74-a5236b6232a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 307]) torch.Size([128]) torch.Size([128, 307])\n",
      "tensor([[ 2,  3,  3,  ...,  0,  0,  0],\n",
      "        [29, 12,  4,  ...,  0,  0,  0],\n",
      "        [12,  4,  4,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [12,  1,  6,  ...,  0,  0,  0],\n",
      "        [15, 18,  4,  ...,  0,  0,  0],\n",
      "        [12, 24,  1,  ...,  0,  0,  0]])\n",
      "torch.Size([128, 307])\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0])\n",
      "torch.Size([128])\n",
      "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.]])\n",
      "torch.Size([128, 307])\n"
     ]
    }
   ],
   "source": [
    "# small test of correctness\n",
    "x, y, m = next(iter(train_loader))\n",
    "print(x.shape, y.shape, m.shape)\n",
    "\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(y)\n",
    "print(y.shape)\n",
    "print(m)\n",
    "print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "882156ad-f2e9-4ade-8b18-fa7d87ddfdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, \\\n",
    "                 num_rec_layers=1, rec_layer=nn.LSTM):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # define all layers we need,\n",
    "        # their parameters will be initialized automatically\n",
    "\n",
    "        # nn.Embedding layer turns input sentences into word embeddings\n",
    "        # with input and output dimension given by vocab_size and embedding_dim\n",
    "        # self.word_embeddings = nn.Embedding(embedding_dim)\n",
    "\n",
    "        # depending on the value of num_rec_layers, the corresponding number\n",
    "        # of rec_layers (either RNN or LSTM) with batch_first=True and hidden\n",
    "        # dimension given by hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.num_rec_layers = num_rec_layers\n",
    "        self.rnn1 = rec_layer(embedding_dim, hidden_dim, batch_first=True)\n",
    "        if self.num_rec_layers == 2:\n",
    "            self.rnn2 = rec_layer(hidden_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        # a final linear layer with sigmoid activation with input and output\n",
    "        # dimension given by hidden_dim and 1.\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.hidden2label = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, sentences, mask):\n",
    "        # sentences shape: [B, L], mask shape: [B, L]\n",
    "        # embedding = word_embeddings(embedding_dim)# call your embedding layer, output shape: [B, L, DE]\n",
    "        embedding = self.word_embeddings(sentences)\n",
    "        out, hidden = self.rnn1(embedding)# call your rnn1, output shape: [B, L, DH]\n",
    "        if self.num_rec_layers == 2:\n",
    "            out, hidden = self.rnn2(out, hidden)# call your rnn2, output shape: [B, L, DH]\n",
    "        out = (out*mask[:, :, None]).mean(dim=1) # shape: [B, DH]\n",
    "        res = self.sigmoid(self.hidden2label(out))# call your hidden2label, output shape: [B, 1]\n",
    "        #print(res)\n",
    "        #print(res.shape)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10a0997d-5041-442e-b08e-331f3e5d4084",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(nn.Module):\n",
    "  def __init__(self, net, num_ensemble=5, seed_val=42):\n",
    "      super(Ensemble, self).__init__()\n",
    "      self.ensembles = nn.ModuleList()\n",
    "      self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "      for i in range(num_ensemble):\n",
    "          torch.manual_seed(seed_val*i+1)\n",
    "          if torch.cuda.is_available(): # To randomize init of NNs for Ensembles\n",
    "              torch.cuda.manual_seed(seed_val*i+1)\n",
    "          self.ensembles.append(net[i])\n",
    "\n",
    "      self.final = nn.Linear(num_ensemble, num_ensemble)\n",
    "\n",
    "  def forward(self, X_in_list, m_in_list):\n",
    "      #a = [net(X_in_list[i], m_in_list[i]) for i, net in enumerate(self.ensembles)]\n",
    "      #print(a[0].shape)\n",
    "      #print(a[1].shape)\n",
    "\n",
    "      x = torch.cat([net(X_in_list[i], m_in_list[i]) for i, net in enumerate(self.ensembles)])\n",
    "      x = x.reshape(-1, len(self.ensembles))\n",
    "      x = self.sigmoid(self.final(x))\n",
    "      \n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d900e00-e66a-4b53-8601-9f5dd259d322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b68bb-383b-40dd-8890-0123e63f6ac5",
   "metadata": {},
   "source": [
    "**3. Demo RNN classifier for correctness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e916605e-eeb7-4c20-bd3e-f932707f3a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ensemble(\n",
       "  (ensembles): ModuleList(\n",
       "    (0): LSTMClassifier(\n",
       "      (word_embeddings): Embedding(500, 128)\n",
       "      (rnn1): LSTM(128, 128, batch_first=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (hidden2label): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "    (1): LSTMClassifier(\n",
       "      (word_embeddings): Embedding(500, 128)\n",
       "      (rnn1): LSTM(128, 64, batch_first=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (hidden2label): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "    (2): LSTMClassifier(\n",
       "      (word_embeddings): Embedding(500, 128)\n",
       "      (rnn1): LSTM(128, 256, batch_first=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (hidden2label): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (final): Linear(in_features=3, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm1 = LSTMClassifier(128, 128, 500)\n",
    "lstm2 = LSTMClassifier(128, 64, 500)\n",
    "lstm3 = LSTMClassifier(128, 256, 500)\n",
    "\n",
    "lstm1.to(device)\n",
    "lstm2.to(device)\n",
    "lstm3.to(device)\n",
    "num_of_bagging = 3\n",
    "\n",
    "lstm_list = [lstm1, lstm2, lstm3]\n",
    "\n",
    "lstm = Ensemble(lstm_list, num_of_bagging)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f985106e-b456-4dc0-8194-f2dcc8a81380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3])\n",
      "tensor([[0.4398, 0.5536, 0.3872],\n",
      "        [0.4401, 0.5533, 0.3868],\n",
      "        [0.4389, 0.5531, 0.3850],\n",
      "        [0.4396, 0.5534, 0.3865],\n",
      "        [0.4390, 0.5531, 0.3852],\n",
      "        [0.4390, 0.5531, 0.3847],\n",
      "        [0.4405, 0.5530, 0.3868],\n",
      "        [0.4400, 0.5534, 0.3869],\n",
      "        [0.4396, 0.5535, 0.3868],\n",
      "        [0.4390, 0.5526, 0.3846]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# demo forward pass with the mini-batch that we generated above\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x1, y1, m1 = next(iter(train_loader))\n",
    "x1 = x1.to(device)\n",
    "y1 = y1.to(device)\n",
    "m1 = m1.to(device)\n",
    "\n",
    "x2, y2, m2 = next(iter(train_loader))\n",
    "x2 = x2.to(device)\n",
    "y2 = y2.to(device)\n",
    "m2 = m2.to(device)\n",
    "\n",
    "x3, y3, m3 = next(iter(train_loader))\n",
    "x3 = x3.to(device)\n",
    "y3 = y3.to(device)\n",
    "m3 = m3.to(device)\n",
    "\n",
    "x = [x1, x2, x3]\n",
    "y = [y1, y2, y3]\n",
    "m = [m1, m2, m3]\n",
    "     \n",
    "y_pred = lstm(x, m)\n",
    "print(y_pred.shape)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af613ac8-7a40-4cca-9585-45fc481f9af0",
   "metadata": {},
   "source": [
    "**4. The final training / testing loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96e83d4e-ebe4-4943-8a36-18e171ba063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(bagging_data, model, lossfun, optimizer, device, n_bagging):\n",
    "    inputs, labels, mask = cook_data(bagging_data, n_bagging)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # # iterate over mini-batches\n",
    "    # for it, (inputs, labels, mask) in enumerate(bagging_data[i]):\n",
    "    #     # move everything to the device\n",
    "    inputs = [i.to(device) for i in inputs]\n",
    "    labels = [i.to(device) for i in labels]\n",
    "    mask = [i.to(device) for i in mask]\n",
    "\n",
    "    model.zero_grad()\n",
    "    # forward pass\n",
    "    output = model(inputs, mask)\n",
    "\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    labels = labels.float()\n",
    "\n",
    "    loss = lossfun(output.view(-1), labels.view(-1))\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # update model parameters\n",
    "    optimizer.step()\n",
    "\n",
    "def evaluate(bagging_data, model, lossfun, device, n_bagging, outer_eval=False):\n",
    "    inputs, labels, mask = cook_data(bagging_data, n_bagging, outer_eval)\n",
    "    \n",
    "    model.eval()\n",
    "    total_acc = 0.0\n",
    "    total_loss = 0.0\n",
    "    # iterate over mini-batches\n",
    "\n",
    "    inputs = [i.to(device) for i in inputs]\n",
    "    labels = [i.to(device) for i in labels]\n",
    "    mask = [i.to(device) for i in mask]\n",
    "\n",
    "    model.zero_grad()\n",
    "    # forward pass\n",
    "    output = model(inputs, mask)\n",
    "\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    labels = labels.float()\n",
    "\n",
    "    loss = lossfun(output.view(-1), labels.view(-1))\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    # calculate test accuracy\n",
    "    pred = output.view(-1) > 0.5\n",
    "    correct = (pred == labels.view(-1).bool())\n",
    "    total_acc += torch.sum(correct).item() / len(correct)\n",
    "\n",
    "    return total_loss, total_acc\n",
    "\n",
    "def cook_data(bagging_data_list, num_of_bagging, outer_eval=False):     \n",
    "    if outer_eval == False:\n",
    "        X = [[] for _ in range(num_of_bagging)]\n",
    "        y = [[] for _ in range(num_of_bagging)]\n",
    "        m = [[] for _ in range(num_of_bagging)]\n",
    "    \n",
    "        count = 0\n",
    "        \n",
    "        for d_l in bagging_data_list:\n",
    "            for it, (inputs, labels, mask) in enumerate(d_l):\n",
    "                X[count].append(inputs)\n",
    "                y[count].append(labels)\n",
    "                m[count].append(mask)\n",
    "            count += 1\n",
    "    \n",
    "        #print(X)\n",
    "        #print(len(X))\n",
    "    \n",
    "        X = [torch.cat(i, dim=0) for i in X]\n",
    "        y = [torch.cat(i, dim=0) for i in y]\n",
    "        m = [torch.cat(i, dim=0) for i in m]\n",
    "        \n",
    "        return X, y, m\n",
    "        \n",
    "    else:\n",
    "        X = [[]]\n",
    "        y = [[]]\n",
    "        m = [[]]\n",
    "    \n",
    "        count = 0\n",
    "        \n",
    "        for d_l in bagging_data_list:\n",
    "            for it, (inputs, labels, mask) in enumerate(d_l):\n",
    "                X[count].append(inputs)\n",
    "                y[count].append(labels)\n",
    "                m[count].append(mask)\n",
    "            count += 1\n",
    "    \n",
    "        #print(X)\n",
    "        #print(len(X))\n",
    "    \n",
    "        X = [torch.cat(i, dim=0) for i in X]\n",
    "        y = [torch.cat(i, dim=0) for i in y]\n",
    "        m = [torch.cat(i, dim=0) for i in m]\n",
    "        \n",
    "        return X, y, m\n",
    "\n",
    "def train(n, split, n_bagging, whole_data, model, lossfun, optimizer, \\\n",
    "          device, num_epochs, batch_size):\n",
    "    train_loss_ = []\n",
    "    test_loss_ = []\n",
    "    train_acc_ = []\n",
    "    test_acc_ = []\n",
    "\n",
    "    bagging_train_data_list = []\n",
    "    bagging_test_data_list = []\n",
    "\n",
    "    # for training, we need to train on different dataset\n",
    "    for i in range(n_bagging):\n",
    "        train_loader, test_loader = data_loader(preprocessing(n, whole_data), split, batch_size)\n",
    "        bagging_train_data_list.append(train_loader)\n",
    "        bagging_test_data_list.append(test_loader)\n",
    "\n",
    "    #print(bagging_train_data_list[0])\n",
    "    #print(len(bagging_train_data_list[1]))\n",
    "    \n",
    "    # X, y, m = cook_data(bagging_train_data_list, n_bagging)\n",
    "    # print(len(X))\n",
    "    # print((X[0]))\n",
    "    # print((X[0].shape))\n",
    "    # print((X[1].shape))\n",
    "    # print(len(X[1]))\n",
    "    \n",
    "    # irerate over training epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # at each step, we do a training epoch and evaluate on train and test data\n",
    "        train_epoch(bagging_train_data_list, model, lossfun, optimizer, device, n_bagging)\n",
    "        train_loss, train_acc = evaluate(bagging_train_data_list, model, lossfun, device, n_bagging, outer_eval=False)\n",
    "        train_loss_.append(train_loss)\n",
    "        train_acc_.append(train_acc)\n",
    "        test_loss, test_acc = evaluate(bagging_test_data_list, model, lossfun, device, n_bagging, outer_eval=False)\n",
    "        test_loss_.append(test_loss)\n",
    "        test_acc_.append(test_acc)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:3d}/{num_epochs:3d} '\n",
    "              f'Training Loss: {train_loss_[epoch]:.3f}, Testing Loss: {test_loss_[epoch]:.3f}, '\n",
    "              f'Training Acc: {train_acc_[epoch]:.3f}, Testing Acc: {test_acc_[epoch]:.3f}')\n",
    "\n",
    "    return train_loss_, train_acc_, test_loss_, test_acc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84b124ec-2b21-453a-952b-2e45c2705aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ensemble(\n",
       "  (ensembles): ModuleList(\n",
       "    (0): LSTMClassifier(\n",
       "      (word_embeddings): Embedding(500, 128)\n",
       "      (rnn1): LSTM(128, 128, batch_first=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (hidden2label): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "    (1): LSTMClassifier(\n",
       "      (word_embeddings): Embedding(500, 128)\n",
       "      (rnn1): LSTM(128, 64, batch_first=True)\n",
       "      (rnn2): LSTM(64, 64, batch_first=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (hidden2label): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "    (2): LSTMClassifier(\n",
       "      (word_embeddings): Embedding(500, 128)\n",
       "      (rnn1): LSTM(128, 256, batch_first=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (hidden2label): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (final): Linear(in_features=3, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm1 = LSTMClassifier(128, 128, 500)\n",
    "lstm2 = LSTMClassifier(128, 64, 500, num_rec_layers=2)\n",
    "lstm3 = LSTMClassifier(128, 256, 500)\n",
    "\n",
    "lstm1.to(device)\n",
    "lstm2.to(device)\n",
    "lstm3.to(device)\n",
    "num_of_bagging = 3\n",
    "\n",
    "lstm_list = [lstm1, lstm2, lstm3]\n",
    "\n",
    "lstm = Ensemble(lstm_list, num_of_bagging)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7889f8b6-9296-4ad0-8a42-e9839ff8e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = optim.RMSprop(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "lossfun = nn.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1ab2af0-a861-44a8-8b04-0d216fa5285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1/ 15 Training Loss: 0.572, Testing Loss: 0.569, Training Acc: 0.760, Testing Acc: 0.770\n",
      "Epoch:   2/ 15 Training Loss: 0.555, Testing Loss: 0.552, Training Acc: 0.778, Testing Acc: 0.784\n",
      "Epoch:   3/ 15 Training Loss: 0.544, Testing Loss: 0.538, Training Acc: 0.778, Testing Acc: 0.784\n",
      "Epoch:   4/ 15 Training Loss: 0.538, Testing Loss: 0.528, Training Acc: 0.776, Testing Acc: 0.784\n",
      "Epoch:   5/ 15 Training Loss: 0.534, Testing Loss: 0.526, Training Acc: 0.777, Testing Acc: 0.784\n",
      "Epoch:   6/ 15 Training Loss: 0.530, Testing Loss: 0.523, Training Acc: 0.777, Testing Acc: 0.784\n",
      "Epoch:   7/ 15 Training Loss: 0.531, Testing Loss: 0.526, Training Acc: 0.777, Testing Acc: 0.784\n",
      "Epoch:   8/ 15 Training Loss: 0.528, Testing Loss: 0.521, Training Acc: 0.777, Testing Acc: 0.784\n",
      "Epoch:   9/ 15 Training Loss: 0.524, Testing Loss: 0.519, Training Acc: 0.777, Testing Acc: 0.784\n",
      "Epoch:  10/ 15 Training Loss: 0.524, Testing Loss: 0.517, Training Acc: 0.777, Testing Acc: 0.784\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# let's first train a vanilla RNN\u001b[39;00m\n\u001b[1;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m----> 3\u001b[0m a, b, c, d \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_of_bagging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlossfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 132\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(n, split, n_bagging, whole_data, model, lossfun, optimizer, device, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m#print(bagging_train_data_list[0])\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m#print(len(bagging_train_data_list[1]))\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# irerate over training epochs\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# at each step, we do a training epoch and evaluate on train and test data\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbagging_train_data_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlossfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_bagging\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m evaluate(bagging_train_data_list, model, lossfun, device, n_bagging, outer_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    134\u001b[0m     train_loss_\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[27], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(bagging_data, model, lossfun, optimizer, device, n_bagging)\u001b[0m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 20\u001b[0m, in \u001b[0;36mEnsemble.forward\u001b[0;34m(self, X_in_list, m_in_list)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_in_list, m_in_list):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#a = [net(X_in_list[i], m_in_list[i]) for i, net in enumerate(self.ensembles)]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#print(a[0].shape)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#print(a[1].shape)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([net(X_in_list[i], m_in_list[i]) \u001b[38;5;28;01mfor\u001b[39;00m i, net \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensembles)])\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensembles))\n\u001b[1;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal(x))\n",
      "Cell \u001b[0;32mIn[20], line 20\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_in_list, m_in_list):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#a = [net(X_in_list[i], m_in_list[i]) for i, net in enumerate(self.ensembles)]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#print(a[0].shape)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#print(a[1].shape)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_in_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_in_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, net \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensembles)])\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensembles))\n\u001b[1;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal(x))\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 31\u001b[0m, in \u001b[0;36mLSTMClassifier.forward\u001b[0;34m(self, sentences, mask)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentences, mask):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# sentences shape: [B, L], mask shape: [B, L]\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# embedding = word_embeddings(embedding_dim)# call your embedding layer, output shape: [B, L, DE]\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embeddings(sentences)\n\u001b[0;32m---> 31\u001b[0m     out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# call your rnn1, output shape: [B, L, DH]\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_rec_layers \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     33\u001b[0m         out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn2(out, hidden)\u001b[38;5;66;03m# call your rnn2, output shape: [B, L, DH]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/rnn.py:881\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    878\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 881\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    885\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# let's first train a vanilla RNN\n",
    "batch_size = 64\n",
    "a, b, c, d = train(3000, 0.2, num_of_bagging, f_data, lstm, lossfun, \\\n",
    "                   optimizer, device, num_epochs=15, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87b5c11a-03e4-4298-9d5e-1e9154b210e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_bagging_train_data_list = []\n",
    "# new_bagging_test_data_list = []\n",
    "\n",
    "# new_train_loader, new_test_loader = data_loader(preprocessing(3000, f_data), 0.2, batch_size)\n",
    "\n",
    "# for i in range(num_of_bagging):\n",
    "#     new_bagging_train_data_list.append(new_train_loader)\n",
    "#     new_bagging_test_data_list.append(new_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6c65700-e0bd-4319-b76c-285e2acfd231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = evaluate(new_bagging_train_data_list, rnn, lossfun, device, num_of_bagging, outer_eval=False)\n",
    "# print(test_loss)\n",
    "# print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
